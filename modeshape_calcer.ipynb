{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import functools\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "import collections\n",
    "sns.set_style(\"white\", {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\", \"Palatino\", \"serif\"]\n",
    "})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "all_data = pd.read_csv('notebook_analysis/intact_whitenoise_1_100Hz.csv')\n",
    "coorddata = pd.read_csv('notebook_analysis/node_coords.csv',\n",
    "                        dtype={'Node':numpy.int64},index_col='Node')\n",
    "\n",
    "def translater(nodeax):\n",
    "    node, ax = int(nodeax[0:-1]),nodeax[-1]\n",
    "    translat = coorddata['Index'].to_dict()\n",
    "    return translat[node]+ax\n",
    "nodes = [63,41,15,95,96,53,55,31,22,17,18,56,58,61,64,43,46,49,68,32,37,39,40,69]\n",
    "allnodes = [i for i in coorddata.index.tolist() if i <100]\n",
    "print(allnodes)\n",
    "neighborhoods = {node:[node%4] for node in allnodes}\n",
    "biggest_modx = lambda lst, x: max([i for i in lst if i%4==x])\n",
    "largesteach = [(i,biggest_modx(allnodes, i)) for i in range(4)]\n",
    "for i,largest in largesteach:\n",
    "    if i+1 in range(4):\n",
    "        neighborhoods[largest].append(i+1)\n",
    "print(neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1)\n",
    "def get_fs(data, f):\n",
    "    #eg f= 100 hz, duration =60s\n",
    "    nbins = int(len(data)/2)\n",
    "    nyquist = f/2\n",
    "    stepsize = nyquist/nbins\n",
    "    fftbins = [i*stepsize for i in range(nbins)]\n",
    "    return fftbins\n",
    "def maxer(fs,response):\n",
    "    biggest = sorted(response,key = lambda x: abs(x), reverse=True)[:10]\n",
    "    def getvals(x):\n",
    "        idx = response.index(x)\n",
    "        return idx, fs[idx]\n",
    "    return [getvals(i) for i in biggest]\n",
    "data = all_data['41x'].tolist()[0:2**12]\n",
    "fft = list(map(abs, np.fft(data)))\n",
    "fs = get_fs(data, 100)\n",
    "ax.plot(fs, fft[0:2048], color = '#737373', linewidth=1)\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_xlim([0,50])\n",
    "ax.set_ylim([10**-3, 10**0])\n",
    "ax.set_yscale('log')\n",
    "sns.despine()\n",
    "#print('largest response at {}Hz, index{}'.format(*maxer(fs, fft[0:2048])))\n",
    "maxer(fs, fft[0:2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samplestream(nodes, all_data):\n",
    "    all_idxs = (str(x)+y for x,y in itertools.product(nodes, ['x','y','z']))\n",
    "    return [(x, all_data[translater(x)].tolist()[0:2**12]) for x in all_idxs]\n",
    "def mapper(d):\n",
    "    idx = 616\n",
    "    nodeid, data = d\n",
    "    ftpeak = np.fft(data)[idx]\n",
    "    c = lambda d: (round(d.real,6),round(d.imag,6))\n",
    "    return [(0,(nodeid,c(ftpeak)))]\n",
    "def shuffler(kvstream):\n",
    "    flat = list(itertools.chain(*kvstream))\n",
    "    sortedkvs = sorted(flat, key=lambda x: x[0])\n",
    "    grouped = itertools.groupby(sortedkvs, key=lambda x:x[0])\n",
    "    return ((k,[i[1] for i in g]) for k,g in grouped)\n",
    "def reducer(kvs):\n",
    "    k,vs =kvs\n",
    "    ws = [complex(*i[1]) for i in vs]\n",
    "    G = np.spectral_mat(ws)\n",
    "    eig = np.pagerank(G)\n",
    "    c = lambda d: (round(d.real,2),round(d.imag,2))\n",
    "    ms = [(vs[idx][0],c(el)) for idx,el in enumerate(eig)]\n",
    "    return (k,ms)\n",
    "def dmapper(neighborhoods, d):\n",
    "    nodeid, data = d\n",
    "    nodenum, nodeax = int(nodeid[0:-1]), nodeid[-1]\n",
    "    hoods = neighborhoods[nodenum]\n",
    "    idx = 616\n",
    "    ftpeak = np.fft(data)[idx]\n",
    "    c = lambda d: (round(d.real,6),round(d.imag,6))\n",
    "    hoods = hoods if nodeax=='x' else [hoods[0]]\n",
    "    return [(i,(nodeid, c(ftpeak))) for i in hoods]\n",
    "\n",
    "def mr(streamfun, mapfun, redfun):\n",
    "    mappit = functools.partial(map, mapfun)\n",
    "    reducit = functools.partial(map,redfun)\n",
    "    return list(reducit(shuffler(mappit(streamfun()))))\n",
    "def merger(lst):\n",
    "    accer = lambda acc, el: acc+el[1]\n",
    "    return functools.reduce(accer, lst,[])\n",
    "def dfdd_merger(lst):\n",
    "    \"\"\"for example [('0',[('a',(1,2)),('b',(3,4))],\n",
    "                    ('1',[('b',(2,3)),('c',(4,5))]) -? to equalise bs, must subtract (1,1) from everything in 2\n",
    "                    ]\n",
    "    should return [('a',(1,2)),('b',(3,4)),('c',(3+4))\n",
    "    \"\"\"\n",
    "    def accer(acc, el):\n",
    "        def tuplediff(x,y):\n",
    "            return (x[0], (x[1][0]-y[1][0],x[1][1]-y[1][1]))\n",
    "        def tupleadd(x,y):\n",
    "            return (x[0], (x[1][0]+y[1][0],x[1][1]+y[1][1]))\n",
    "        def match_or_none(lst, key):\n",
    "            try:\n",
    "                matcher = next((i for i in allcombs if key(i)))\n",
    "                return matcher\n",
    "            except StopIteration:\n",
    "                return \n",
    "        newnodes = el[1]\n",
    "        allcombs = list(itertools.product(acc, newnodes))\n",
    "        matcher = match_or_none(allcombs, key=lambda i: i[0][0]==i[1][0])\n",
    "        diff = tuplediff(*matcher) if matcher else ('None',(0,0))\n",
    "        print('diff: ', diff)\n",
    "        superposed = [tupleadd(i,diff) for i in newnodes]\n",
    "        acc.update(superposed)\n",
    "        return acc\n",
    "    return functools.reduce(accer, lst, set())\n",
    "import functools\n",
    "    #return functools.reduce(accer, lst, set())\n",
    "dfdd_merger([('0',[('a',(1,2)),('b',(3,4))]),\n",
    "             ['1',[('b',(2,3)),('c',(4,5))]],\n",
    "             ['2',[('c',(1,3)),('e',(9,1))]]\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = functools.partial(samplestream,allnodes, all_data)\n",
    "r = mr(stream, mapper, reducer)\n",
    "res = merger(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamdfdd = functools.partial(samplestream, allnodes, all_data)\n",
    "dfddmapper=functools.partial(dmapper,neighborhoods)\n",
    "rdfdd = mr(streamdfdd, dfddmapper, reducer)\n",
    "resdfdd = dfdd_merger(rdfdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realify(amplitude, phase):\n",
    "    \"\"\"take complex mode shape, which means we can express structural\n",
    "    motion at each point as something like a*sin(wt+phi),\n",
    "    and return a real value which is a snapshot of this steady state\n",
    "    motion at t=0\"\"\"\n",
    "    t=0\n",
    "    w=_\n",
    "    print('a, phi',amplitude, phase)\n",
    "    return abs(complex(amplitude, phase))#amplitude*math.sin(phase)\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "def mergeaxes(entries):\n",
    "    \"\"\"entries is a list of modeshape values for\n",
    "    a specific node,for example:\n",
    "    [{'ax': 'x', 'Node': '31', 'val': -0.03}\n",
    "    , {'ax': 'y', 'Node': '31', 'val': 0.05}]\"\"\"\n",
    "    convert = lambda d: {'Node':d['Node'],2*d['ax']:d['val']}\n",
    "    return functools.reduce(merge_two_dicts, map(convert, entries),{})\n",
    "def formatter(res):\n",
    "    d = [{'Node':k[0:-1],'ax':k[-1], 'val':realify(*v)} for k,v in res]\n",
    "    print('d: ',d)\n",
    "    sortedd = sorted(d, key=lambda d:d['Node'])\n",
    "    grouped = itertools.groupby(sortedd, key = lambda d:d['Node'])\n",
    "    res = [mergeaxes(group) for k, group in grouped]\n",
    "    print('res: ',res)\n",
    "    return pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = formatter(res)\n",
    "final.to_csv('notebook_analysis/fddmodeshape.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal = formatter(resdfdd)\n",
    "dfinal.to_csv('notebook_analysis/dfddmodeshape.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
